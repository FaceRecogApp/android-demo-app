# 项目

1. 执法记录仪类似，要求视频realtime上传，或者存储。
2. 视频的解析，找到人脸并确定身份信息。（需要negative样本）



## 使用android平台搭建model

new
- [x] 将pytorch模型保存为script
- [x] 在android studio中读取pytorch模型，运行，获取输出
- [x] 对输出判断是否超过prob threshold
- [x] 将超过的输出nms
- [x] 将最终的输出画框
- 将框中的人脸使用websocket传到服务器上，等待结果。
- [x] 1. 将图片和box转化成字节流通过websocket传输
- [x] 2. 在服务器解码图片和box
- [x] 3. 在客户端扩大人脸图片的尺寸，确保整张脸包括进来，获取更多信息
- [x] 4. 在客户端设置按时进行请求而不是按按钮
- [x] 5. 在服务器上运行模型
- [x] 6. 将结果打包成json字符串传给客户端
- [x] 7. 客户端将json中的box和信息加入到预备池中
- [x] 8. 客户端在画框的时候检查预备池中的box，如果iou较大，则采用该box，将其对应的信息简要画出
- [x] 9. 判断哪个框距离中心最近，认为这个框是注意框，将这个框对应的信息（如果有的话）写入到下面的状态栏中。
- [x] 10. namedbox更新规则，为了降低请求服务器的次数，使用namebox保存上一次请求的信息，如果在一次绘图中，有的框没有被使用到，可以认为该框已经失效，将其设置为is_valid=false;
- [x] 11. 在服务器端添加数据库，使其能够输出更多信息
  
- [ ] 12. 数据加密问题呢
- [ ] 13. 在客户端加入设置ws ip的功能
- [ ] 14. 显示人脸框不准确的问题
- [ ] 15. 服务器端录入信息
- [x] 16. 服务器端返回信息包括top_k
- [x] 17. 客户端上传视频流或者保存视频流
- [x] 18. 在数据传输时的格式，在json中包括一个tag，告知服务器bitmap是仅人脸或整个图片。


## 其他问题：

1. 是否使用本地人脸判断：即是否使用上一次已经判断出的人脸结果来应对重新框取到的人脸，降低服务器的压力，提高客户端的压力。
2. 或者可以使用其他的方式降低和服务器交互的频率，如使用按钮才检测人脸的方式，或者每过了一秒才交互。





# 第二计划

使用可推流，可录像的demo作为基础，服务器端使用websocket和客户端连接，客户端使用rtmp协议推流，将流字符串通过websocket发送给服务器，服务器启动模型，分析其中的帧，将结果返回给客户端。客户端使用graphoverlay将返回的框画在图像上。

- [x] 测试修正demo的录像功能。
- [ ] demo只有在pulish的情况下才能录像，修改代码使其能够在不publish的情况下（无网络）保存视频到本地。
- [x] 给demo加入websocket。
- [x] 给服务器加入分析部分。
- [x] 给demo加入graphoverlay和相关的画框部分（该部分应当是具备多个接口的抽象的部分，以便于后来可以框出更多的物体或行为等）。



## 改进

- [ ] 1. 界面要改进，要能够显示更多信息。

     界面改进：

     - [ ] 应当至少具备以下几个页面：选择界面：选择将要使用的模型，选择使用远程还是本地检测。

       ​												  设置界面：设置服务器的地址

       ​												  数据包下载界面：根据用户需求，和服务器沟通，返回可下载的数据包
		 - [ ] 在远程和本地识别界面都应该有以下信息显示：在图像中，框的上方（或周围）显示框中物体的主要信息；在图像下方或者右方（根据视频的size）显示居中框的详细信息。
- [ ] 2. 网络结构改进，使其能够更准确
- [ ] 3. 服务器也要录视频
- [ ] 4. 使用数据包的本地人脸识别

     在pytorch demo中加入人脸识别的相关算法，在服务器加入请求人脸数据包的相关代码。

     在用户切换到本地识别的选项后，人脸识别部分算法会读取所有的本地包，在识别阶段使用包中的数据。

     服务器下载包的过程应当是由服务器压缩包，传输，本地解压包。





## 大纲

两条线：

1. pytorch demo线，专门走本地识别，支持本地录像，下载包，本地识别等算法。（后面可能加入本地识别其他物体的模型和功能）
2. yasea线，专门走远程识别，支持本地录像，rtmp。（后面可能加入其他模型的服务器端支持）



## 任务

1. 给pytorch demo加入基于camerax的录像功能
   任务结果：失败，因为camerax的videocapture功能尚且处于测试阶段，设备兼容性查，替代方案为使用bitmap合成mp4流（这样会没有声音和低帧数）

2. 给pytorch demo加入本地的人脸识别算法

3. 尝试将yasea加入到pytroch demo，并给其加入界面使其能够显示更多信息。

4. 尝试是服务器可以建立多个websocket连接

   



## 接口

1. 数据格式

   {"message": "message received", 

    "count":3,

    "id": ["xf"],

    "id_k": [["xf", "zsy", "dh"]], 

    "id_k_index": [[7, 11, 0]], 

    "face_distances_k": [[0.9147695899009705, 0.9746761322021484, 0.9667826890945435, 1.1123324632644653, 1.035972237586975, 1.0312578678131104, 1.1599266529083252, 0.7479943037033081, 1.1573818922042847, 1.0324608087539673, 1.0902680158615112, 0.8068807125091553]],

    "career": "gakuse",

    "prob": [[0.11383781328970093, 0.10325552440182816, 0.08921396800201366]],

    "box": [[0.2361111044883728, 0.4854166805744171, 0.6625000238418579, 0.8052083253860474]]}

2. 客户端请求服务器数据格式

   ｛"message":"whole_image" / "rtmp stream" / "get embeddings" / "",

   ｝





## 前端识别流程设计

1. 《登录页面》用户使用<u>执法人员</u>账号+密码登录进入软件的《选择界面》。

2. 《选择页面》用户在选择页面选择接下来所要使用的功能跳转进入不同的《识别界面》，websocket根据用户的选择向服务器传送数据告知应当选择的模型和交互方式。

3. 《识别界面》加载不同的模型和与服务器进行不同的交互。

4. 《设置界面》用户在《选择页面》或《识别界面》可以进入《设置界面》，在此界面中可以设置｛websocket服务器地址，rtmp推流地址（如果是远程识别），视频编码解码方式（如果是远程识别），下载数据包（进入《数据包选择界面》）（如果是本地识别），管理数据包《数据包选择界面》（如果是本地识别）｝。

5. 《数据包选择界面》用户在设置界面中选择下载数据包或管理数据包后进入该界面，在该界面内用户可以查看已经安装的数据包（进行删除操作），可以下载的数据包（进行下载操作）。

6. 《识别界面》之《本地人脸识别》

   1. 页面布局大体一致
   2. 页面的主要工作为：首先加载人脸detection和recognition的两个模型（基于ssd的ultra light face detector用作detection）及（基于resnet的inception_resnet_v1用作人脸的编码/recognition），再将所有的数据包读入内存（一般一个人脸的编码为128维度的float向量，大小不到1kb，所以大多情况下人脸数据都可以读入内存），再开始进行图片的处理过程（对于每个读入的图片进行人脸检测，图片切割，送去人脸编码，将编码的结果和数据包中的编码进行欧氏距离上的比较，返回距离最近的结果作为识别结果），最后将结果画在屏幕上和更新控件。

7.  《识别界面》之《远程人脸识别》

   1. 页面布局大体一致
   2. 页面的主要工作为：首先根据设置中的rtmp地址建立推流器，其次根据websocket地址建立websocket连接，在用户点击《推流》按钮后，通过websocket（发送/得到）rtmp地址，使用推流器推流，websocket连接在收到服务器发来的包括框和人脸相关身份数据的信息后将该信息反馈到屏幕上和控件上。

8. 《登录界面》之《人脸识别登录》

	1. 页面显示简要的提示信息
	2. 页面要求：有网络或已经登陆过一次。
	3. 页面主要工作为：首先通过本地获取已经保存的人脸信息。其次加载模型，打开摄像头获取人脸并编码。如果和本地人脸距离小于阈值，则允许登录。否则将人脸图片（或者编码，取决于服务器的模型是否有更高精度）上传服务器，由服务器判断是否具有登录资格。

   

## 后台管理流程设计

1. 后台设计基于web的服务管理。

2. 《登录页面》后台管理员通过管理员账号和密码登录进入《后台管理页面》。

3. 《后台管理页面》该页面中管理员可以选择以下的功能
   1. 观看rtmp流，页面跳转到《rtmp选择页面》
   2. 上传船员信息，页面跳转到《信息更新页面》
   3. 浏览历史视频，页面跳转到《历史视频页面》
   4. 向船员发布任务，页面跳转到《任务发布页面》
   
4. 《rtmp选择页面》该页面中显示所有当前的rtmp流和推流的<u>执法人员</u>的简要信息，其执行的任务的信息。点击后进入《rtmp播放页面》

5. 《信息更新页面》取决于具体的船员信息组织形式，将信息导入到服务器上。

6. 《历史视频界面》该页面可以浏览所有已经录制和上传的视频和录制视频的<u>执法人员</u>的简要信息，其执行的任务的信息。点击后进入《视频播放页面》

7. 《任务发布页面》该页面可以赋予<u>执法人员</u>一定的任务，（任务包括任务人，任务对象，任务时间等信息）系统会将任务对象包含的人物相关信息打包成一个任务包（包括人脸编码和人物身份信息），并赋予任务人获取该任务包的权限，其可以在前端的《数据包选择界面》获得该数据包并应用。

8. 《rtmp播放页面》播放rtmp流，如果可能，支持对流的处理，在页面上画出处理的结果。

9. 《视频播放页面》播放视频，如果可能，支持对视频的处理，在页面上画出处理的结果。

   



## 服务器功能设计

1. 服务器基于django，使用python开发。
2. 服务器支持后台管理的相关页面。运行web程序。
3. 服务器接收rtmp流并推流，使用srs（simple rtmp server）。
4. 服务器接收到rtmp流将其编码为视频。
5. 信息更新：服务器在收到后台信息更新的要求后，将信息处理，加入到正在运行的程序的数据中。
6. 任务相关：
   1. 服务器在收到后台任务发布的要求后，将相关的任务对象的人脸编码和信息打包成数据包。并赋予<u>执法人员</u> 权限使其能够查询和下载该数据包。
   2. 服务器在收到前台的任务查询（数据包查询的要求后），根据请求发起者的权限返回其任务列表并在其选择数据包后传输数据包。
7. 服务器部署在有域名的公网服务器上使其能够通过域名被访问到。
8. 如果可能，完成后台管理设计的《rtmp播放页面》和《视频播放页面》的扩展部分。

